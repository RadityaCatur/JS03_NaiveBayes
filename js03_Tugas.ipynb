{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Tugas\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Tugas 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Menggunakan data `spam.csv`\\n\",\n",
    "    \"2. Fitur `CountVectorizer` dengan mengaktifkan **stop_words**\\n\",\n",
    "    \"3. Evaluasi hasilnya\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Tugas 2\\n\",\n",
    "    \"\\n\",\n",
    "    \"Buatlah model klasfikasi Multinomial Naive Bayes dengan ketentuan,\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Menggunakan data `spam.csv`\\n\",\n",
    "    \"2. Fitur `TF-IDF` dengan mengaktifkan **stop_words**\\n\",\n",
    "    \"3. Evaluasi hasilnya dan bandingkan dengan hasil tugas 1.\\n\",\n",
    "    \"4. Berikan kesimpulan fitur mana yang terbaik pada kasus data `spam.csv`\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 14,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#Tugas Bagian 1\\n\",\n",
    "    \"#Nama : Diajeng Nidzom Yoesharnilillah\\n\",\n",
    "    \"#Kelas: TI3B\\n\",\n",
    "    \"#Absen: 11\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.feature_extraction.text import CountVectorizer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 15,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>Labels</th>\\n\",\n",
    "       \"      <th>SMS</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>ham</td>\\n\",\n",
    "       \"      <td>Go until jurong point, crazy.. Available only ...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>ham</td>\\n\",\n",
    "       \"      <td>Ok lar... Joking wif u oni...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>spam</td>\\n\",\n",
    "       \"      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>ham</td>\\n\",\n",
    "       \"      <td>U dun say so early hor... U c already then say...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>ham</td>\\n\",\n",
    "       \"      <td>Nah I don't think he goes to usf, he lives aro...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ],\n",
    "      \"text/plain\": [\n",
    "       \"  Labels                                                SMS\\n\",\n",
    "       \"0    ham  Go until jurong point, crazy.. Available only ...\\n\",\n",
    "       \"1    ham                      Ok lar... Joking wif u oni...\\n\",\n",
    "       \"2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\\n\",\n",
    "       \"3    ham  U dun say so early hor... U c already then say...\\n\",\n",
    "       \"4    ham  Nah I don't think he goes to usf, he lives aro...\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 15,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('spam.csv')\\n\",\n",
    "    \"df = df.drop(df.iloc[:,2:], axis=1)\\n\",\n",
    "    \"new_cols = {\\n\",\n",
    "    \"    'v1': 'Labels',\\n\",\n",
    "    \"    'v2': 'SMS'\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = df.rename(columns=new_cols)\\n\",\n",
    "    \"X = df['SMS'].values\\n\",\n",
    "    \"y = df['Labels'].values\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>Labels</th>\\n\",\n",
    "       \"      <th>SMS</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>Go until jurong point, crazy.. Available only ...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>Ok lar... Joking wif u oni...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>U dun say so early hor... U c already then say...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>Nah I don't think he goes to usf, he lives aro...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ],\n",
    "      \"text/plain\": [\n",
    "       \"   Labels                                                SMS\\n\",\n",
    "       \"0       0  Go until jurong point, crazy.. Available only ...\\n\",\n",
    "       \"1       0                      Ok lar... Joking wif u oni...\\n\",\n",
    "       \"2       1  Free entry in 2 a wkly comp to win FA Cup fina...\\n\",\n",
    "       \"3       0  U dun say so early hor... U c already then say...\\n\",\n",
    "       \"4       0  Nah I don't think he goes to usf, he lives aro...\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 2,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"new_labels = {\\n\",\n",
    "    \"    'spam': 1,\\n\",\n",
    "    \"    'ham': 0\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"df['Labels'] = df['Labels'].map(new_labels)\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 11,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=70)\\n\",\n",
    "    \"\\n\",\n",
    "    \"bow = CountVectorizer(stop_words='english')\\n\",\n",
    "    \"X_train = bow.fit_transform(X_train)\\n\",\n",
    "    \"X_test = bow.transform(X_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 16,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.naive_bayes import MultinomialNB\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 17,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Hasil akurasi data train: 0.9827238052501682\\n\",\n",
    "      \"Hasil akurasi data test: 0.9766816143497757\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"mnb = MultinomialNB()\\n\",\n",
    "    \"mnb.fit(X_train, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred_train = mnb.predict(X_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"acc_train = accuracy_score(y_train, y_pred_train)\\n\",\n",
    "    \"y_pred_test = mnb.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"acc_test = accuracy_score(y_test, y_pred_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f'Hasil akurasi data train: {acc_train}')\\n\",\n",
    "    \"print(f'Hasil akurasi data test: {acc_test}')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 18,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#Tugas Bagian 2\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.feature_extraction.text import TfidfVectorizer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 19,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=70)\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(stop_words='english')\\n\",\n",
    "    \"X_train = vectorizer.fit_transform(X_train)\\n\",\n",
    "    \"X_test = vectorizer.transform(X_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 20,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Hasil akurasi data train: 0.9827238052501682\\n\",\n",
    "      \"Hasil akurasi data test: 0.9766816143497757\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"from sklearn.naive_bayes import MultinomialNB\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"mnb = MultinomialNB()\\n\",\n",
    "    \"mnb.fit(X_train, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred_train = mnb.predict(X_train)\\n\",\n",
    "    \"acc_train = accuracy_score(y_train, y_pred_train)\\n\",\n",
    "    \"y_pred_test = mnb.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"acc_test = accuracy_score(y_test, y_pred_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f'Hasil akurasi data train: {acc_train}')\\n\",\n",
    "    \"print(f'Hasil akurasi data test: {acc_test}')\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3.8.8 ('base')\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.8\"\n",
    "  },\n",
    "  \"orig_nbformat\": 4,\n",
    "  \"vscode\": {\n",
    "   \"interpreter\": {\n",
    "    \"hash\": \"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186\"\n",
    "   }\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
